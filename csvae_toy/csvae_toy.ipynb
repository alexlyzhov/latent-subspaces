{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.distributions as dists\n",
    "import torch.utils.data as utils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVAE(nn.Module):\n",
    "    def __init__(self, input_dim, labels_dim, z_dim, w_dim):\n",
    "        super(CSVAE, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.labels_dim = labels_dim\n",
    "        self.z_dim = z_dim\n",
    "        self.w_dim = w_dim\n",
    "        \n",
    "        self.encoder_xy_to_w = nn.Sequential(nn.Linear(input_dim+labels_dim, w_dim), nn.ReLU(), nn.Linear(w_dim, w_dim), nn.ReLU())\n",
    "        self.mu_xy_to_w = nn.Linear(w_dim, w_dim)\n",
    "        self.logvar_xy_to_w = nn.Linear(w_dim, w_dim)\n",
    "        \n",
    "        self.encoder_x_to_z = nn.Sequential(nn.Linear(input_dim, z_dim), nn.ReLU(), nn.Linear(z_dim, z_dim), nn.ReLU())\n",
    "        self.mu_x_to_z = nn.Linear(z_dim, z_dim)\n",
    "        self.logvar_x_to_z = nn.Linear(z_dim, z_dim)\n",
    "        \n",
    "        self.encoder_y_to_w = nn.Sequential(nn.Linear(labels_dim, w_dim), nn.ReLU(), nn.Linear(w_dim, w_dim), nn.ReLU())\n",
    "        self.mu_y_to_w = nn.Linear(w_dim, w_dim)\n",
    "        self.logvar_y_to_w = nn.Linear(w_dim, w_dim)\n",
    "        \n",
    "        # Add sigmoid or smth for images!\n",
    "        self.decoder_zw_to_x = nn.Sequential(nn.Linear(z_dim+w_dim, z_dim+w_dim), nn.ReLU(), nn.Linear(z_dim+w_dim, z_dim+w_dim), nn.ReLU())\n",
    "        self.mu_zw_to_x = nn.Linear(z_dim+w_dim, input_dim)\n",
    "        self.logvar_zw_to_x = nn.Linear(z_dim+w_dim, input_dim)\n",
    "\n",
    "        self.init_params()\n",
    "\n",
    "    def init_params(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "        \n",
    "    def q_zw(self, x, y):\n",
    "        \"\"\"\n",
    "        VARIATIONAL POSTERIOR\n",
    "        :param x: input image\n",
    "        :return: parameters of q(z|x), (MB, hid_dim)\n",
    "        \"\"\"\n",
    "        xy = torch.cat([x, y], dim=1)\n",
    "        \n",
    "        intermediate = self.encoder_x_to_z(x)\n",
    "        z_mu = self.mu_x_to_z(intermediate)\n",
    "        z_logvar = self.mu_x_to_z(intermediate)\n",
    "        \n",
    "        intermediate = self.encoder_xy_to_w(xy)\n",
    "        w_mu_encoder = self.mu_xy_to_w(intermediate)\n",
    "        w_logvar_encoder = self.mu_xy_to_w(intermediate)\n",
    "        \n",
    "        intermediate = self.encoder_y_to_w(y)\n",
    "        w_mu_prior = self.mu_y_to_w(intermediate)\n",
    "        w_logvar_prior = self.mu_y_to_w(intermediate)\n",
    "        \n",
    "        return w_mu_encoder, w_logvar_encoder, w_mu_prior, \\\n",
    "               w_logvar_prior, z_mu, z_logvar\n",
    "    \n",
    "    def p_x(self, z, w):\n",
    "        \"\"\"\n",
    "        GENERATIVE DISTRIBUTION\n",
    "        :param z: latent vector          (MB, hid_dim)\n",
    "        :return: parameters of p(x|z)    (MB, inp_dim)\n",
    "        \"\"\"\n",
    "        \n",
    "        zw = torch.cat([z, w], dim=1)\n",
    "        \n",
    "        intermediate = self.decoder_zw_to_x(zw)\n",
    "        mu = self.mu_zw_to_x(intermediate)\n",
    "        logvar = self.logvar_zw_to_x(intermediate)\n",
    "        \n",
    "        return mu, logvar\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\n",
    "        Encode the image, sample z and decode \n",
    "        :param x: input image\n",
    "        :return: parameters of p(x|z_hat), z_hat, parameters of q(z|x)\n",
    "        \"\"\"\n",
    "        w_mu_encoder, w_logvar_encoder, w_mu_prior, \\\n",
    "            w_logvar_prior, z_mu, z_logvar = self.q_zw(x, y)\n",
    "        w_encoder = self.reparameterize(w_mu_encoder, w_logvar_encoder)\n",
    "        w_prior = self.reparameterize(w_mu_prior, w_logvar_prior)\n",
    "        z = self.reparameterize(z_mu, z_logvar)\n",
    "        \n",
    "        x_mu, x_logvar = self.p_x(z, w_encoder)\n",
    "        return x_mu, x_logvar, \\\n",
    "               w_mu_encoder, w_logvar_encoder, w_mu_prior, \\\n",
    "               w_logvar_prior, z_mu, z_logvar\n",
    "\n",
    "    def reconstruct_x(self, x, y):\n",
    "        x_mean, _, _, _, _ = self.forward(x, y)\n",
    "        return x_mean\n",
    "\n",
    "    def calculate_loss(self, x, y, average=True):\n",
    "        \"\"\"\n",
    "        Given the input batch, compute the negative ELBO \n",
    "        :param x:   (MB, inp_dim)\n",
    "        :param beta: Float\n",
    "        :param average: Compute average over mini batch or not, bool\n",
    "        :return: -RE + beta * KL  (MB, ) or (1, )\n",
    "        \"\"\"\n",
    "        x_mu, x_logvar, \\\n",
    "            w_mu_encoder, w_logvar_encoder, w_mu_prior, \\\n",
    "            w_logvar_prior, z_mu, z_logvar = self.forward(x, y)\n",
    "        \n",
    "        z_dist = dists.MultivariateNormal(z_mu.flatten(), torch.diag(z_logvar.flatten().exp()))\n",
    "        z_prior = dists.MultivariateNormal(torch.zeros(self.z_dim * z_mu.size()[0]), torch.eye(self.z_dim * z_mu.size()[0]))\n",
    "        \n",
    "        w_dist = dists.MultivariateNormal(w_mu_encoder.flatten(), torch.diag(w_logvar_encoder.flatten().exp()))\n",
    "        w_prior = dists.MultivariateNormal(w_mu_prior.flatten(), torch.diag(w_logvar_prior.flatten().exp()))\n",
    "        \n",
    "        z_kl = dists.kl.kl_divergence(z_dist, z_prior)\n",
    "        w_kl = dists.kl.kl_divergence(w_dist, w_prior)\n",
    "\n",
    "        recon = ((x_mu - x)**2).mean(dim=(1))\n",
    "        # alternatively use predicted logvar too to evaluate density of input\n",
    "        \n",
    "        ELBO = 20 * recon + 0.2 * z_kl + 1 * w_kl\n",
    "        \n",
    "        if average:\n",
    "            ELBO = ELBO.mean()\n",
    "            recon = recon.mean()\n",
    "            z_kl = z_kl.mean()\n",
    "            w_kl = w_kl.mean()\n",
    "\n",
    "        return ELBO, recon, z_kl, w_kl\n",
    "\n",
    "#     def calculate_nll(self, X, samples=5000):\n",
    "#         \"\"\"\n",
    "#         Estimate NLL by importance sampling\n",
    "#         :param X: dataset, (N, inp_dim)\n",
    "#         :param samples: Samples per observation\n",
    "#         :return: IS estimate\n",
    "#         \"\"\"   \n",
    "#         prob_sum = 0.\n",
    "\n",
    "#         for i in range(samples):\n",
    "#             KL, RE, _ = self.calculate_loss(X)\n",
    "#             prob_sum += (KL + RE).exp_()\n",
    "            \n",
    "#         return - (prob_sum / samples).sum().log_()\n",
    "\n",
    "#     def generate_x(self, N=25):\n",
    "#         \"\"\"\n",
    "#         Sample, using you VAE: sample z from prior and decode it \n",
    "#         :param N: number of samples\n",
    "#         :return: X (N, inp_size)\n",
    "#         \"\"\"\n",
    "\n",
    "#         m = MultivariateNormal(torch.zeros(self.z_dim + self.w_dim), torch.eye(self.z_dim + self.w_dim))\n",
    "#         z = m.sample(sample_shape=torch.Size([N])) \n",
    "        \n",
    "#         X, _ = self.p_x(z.cuda())\n",
    "#         return X\n",
    "\n",
    "    @staticmethod\n",
    "    def reparameterize(mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = torch.FloatTensor(std.size()).normal_().to(mu.device)\n",
    "        return eps.mul(std).add_(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, manifold_x = make_swiss_roll(n_samples=10000)\n",
    "x = x.astype(np.float32)\n",
    "y = (x[:, 0:1] >= 10).astype(np.float32)\n",
    "z_dim = 2\n",
    "w_dim = 2\n",
    "\n",
    "batch_size = 32\n",
    "beta = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_tensor = torch.from_numpy(x)\n",
    "train_set_y_tensor = torch.from_numpy(y)\n",
    "train_set = utils.TensorDataset(train_set_x_tensor, train_set_y_tensor)\n",
    "train_loader = utils.DataLoader(train_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CSVAE(input_dim, z_dim, w_dim).cuda()\n",
    "model = CSVAE(input_dim=x.shape[1], labels_dim=y.shape[1], z_dim=z_dim, w_dim=w_dim)\n",
    "model = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2300 [00:00<?, ?it/s]/home/aglyzhov/miniconda3/envs/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:21: RuntimeWarning: Mean of empty slice.\n",
      "/home/aglyzhov/miniconda3/envs/myenv/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "  0%|          | 1/2300 [00:04<2:53:09,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Mean MSE: 83.7713\n",
      "Mean KL: nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2300 [00:09<2:55:18,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Mean MSE: 79.2024\n",
      "Mean KL: nan\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-223-c93814b34699>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mcur_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon_loss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_kl_loss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_kl_loss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcur_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-219-5cf6160e30df>\u001b[0m in \u001b[0;36mcalculate_loss\u001b[0;34m(self, x, y, average)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mx_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_logvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mw_mu_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_logvar_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_mu_prior\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mw_logvar_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_logvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mz_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_logvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-219-5cf6160e30df>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \"\"\"\n\u001b[1;32m     77\u001b[0m         \u001b[0mw_mu_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_logvar_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_mu_prior\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mw_logvar_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_logvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_zw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mw_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_mu_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_logvar_encoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mw_prior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_mu_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_logvar_prior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-219-5cf6160e30df>\u001b[0m in \u001b[0;36mq_zw\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mintermediate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_y_to_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mw_mu_prior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu_y_to_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mw_logvar_prior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu_y_to_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mw_mu_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_logvar_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_mu_prior\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=1e-3/2)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(opt, milestones=[pow(3, i) for i in range(7)], gamma=pow(0.1, 1/7))\n",
    "n_epochs = 2300\n",
    "\n",
    "mse_losses = []\n",
    "z_kl_losses = []\n",
    "w_kl_losses = []\n",
    "for epoch_i in trange(n_epochs):\n",
    "    for cur_batch in train_loader:\n",
    "        cur_batch = cur_batch\n",
    "        opt.zero_grad()\n",
    "        loss_val, recon_loss_val, z_kl_loss_val, w_kl_loss_val = model.calculate_loss(*cur_batch)\n",
    "        loss_val.backward()\n",
    "        opt.step()\n",
    "        mse_losses.append(recon_loss_val.item())\n",
    "        z_kl_losses.append(z_kl_loss_val.item())\n",
    "        w_kl_losses.append(w_kl_loss_val.item())\n",
    "    scheduler.step()\n",
    "    print(f'Epoch {epoch_i}')\n",
    "    print(f'Mean MSE: {np.array(mse_losses[-len(train_loader):]).mean():.4f}')\n",
    "    print(f'Mean KL: {np.array(kl_losses[-len(train_loader):]).mean():.4f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing process\n",
    "\n",
    "x_test, manifold_x_test = make_swiss_roll(n_samples=10000)\n",
    "x_test = x_test.astype(np.float32)\n",
    "test_set_tensor = torch.from_numpy(x_test)\n",
    "mu_x, logvar_x, z_hat, mu_z, logvar_z = model.forward(test_set_tensor)\n",
    "\n",
    "labels_test = (x_test[:, 0:1] >= 10)\n",
    "colors_test = ['red' if label[0] else 'blue' for label in labels_test]\n",
    "\n",
    "z_hat = z_hat.detach().numpy()\n",
    "z_comp = z_hat[:, :2]\n",
    "w_comp = z_hat[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usual VAE results\n",
    "\n",
    "plt.figure(figsize=(5, 5,))\n",
    "plt.title('(z1, z2)')\n",
    "plt.scatter(z_comp[:, 0], z_comp[:, 1], c=colors_test)\n",
    "\n",
    "plt.figure(figsize=(5, 5,))\n",
    "plt.title('(z2, w1)')\n",
    "plt.scatter(z_comp[:, 1], w_comp[:, 0], c=colors_test)\n",
    "\n",
    "plt.figure(figsize=(5, 5,))\n",
    "plt.title('(w1, w2)')\n",
    "plt.scatter(w_comp[:, 0], w_comp[:, 1], c=colors_test)\n",
    "\n",
    "plt.figure(figsize=(5, 5,))\n",
    "plt.title('(w2, z1)')\n",
    "plt.scatter(w_comp[:, 1], w_comp[:, 0], c=colors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
