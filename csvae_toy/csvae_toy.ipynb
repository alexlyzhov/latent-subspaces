{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.distributions as dists\n",
    "import torch.utils.data as utils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVAE(nn.Module):\n",
    "    def __init__(self, input_dim, labels_dim, z_dim, w_dim):\n",
    "        super(CSVAE, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.labels_dim = labels_dim\n",
    "        self.z_dim = z_dim\n",
    "        self.w_dim = w_dim\n",
    "        \n",
    "        self.encoder_xy_to_w = nn.Sequential(nn.Linear(input_dim+labels_dim, w_dim), nn.ReLU(), nn.Linear(w_dim, w_dim), nn.ReLU())\n",
    "        self.mu_xy_to_w = nn.Linear(w_dim, w_dim)\n",
    "        self.logvar_xy_to_w = nn.Linear(w_dim, w_dim)\n",
    "        \n",
    "        self.encoder_x_to_z = nn.Sequential(nn.Linear(input_dim, z_dim), nn.ReLU(), nn.Linear(z_dim, z_dim), nn.ReLU())\n",
    "        self.mu_x_to_z = nn.Linear(z_dim, z_dim)\n",
    "        self.logvar_x_to_z = nn.Linear(z_dim, z_dim)\n",
    "        \n",
    "        self.encoder_y_to_w = nn.Sequential(nn.Linear(labels_dim, w_dim), nn.ReLU(), nn.Linear(w_dim, w_dim), nn.ReLU())\n",
    "        self.mu_y_to_w = nn.Linear(w_dim, w_dim)\n",
    "        self.logvar_y_to_w = nn.Linear(w_dim, w_dim)\n",
    "        \n",
    "        # Add sigmoid or smth for images!\n",
    "        self.decoder_zw_to_x = nn.Sequential(nn.Linear(z_dim+w_dim, z_dim+w_dim), nn.ReLU(), nn.Linear(z_dim+w_dim, z_dim+w_dim), nn.ReLU())\n",
    "        self.mu_zw_to_x = nn.Linear(z_dim+w_dim, input_dim)\n",
    "        self.logvar_zw_to_x = nn.Linear(z_dim+w_dim, input_dim)\n",
    "        \n",
    "        self.decoder_z_to_y = nn.Sequential(nn.Linear(z_dim, z_dim), nn.ReLU(), nn.Linear(z_dim, z_dim), nn.ReLU(),\n",
    "                                            nn.Linear(z_dim, labels_dim), nn.Sigmoid())\n",
    "\n",
    "        self.init_params()\n",
    "\n",
    "    def init_params(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "        \n",
    "    def q_zw(self, x, y):\n",
    "        \"\"\"\n",
    "        VARIATIONAL POSTERIOR\n",
    "        :param x: input image\n",
    "        :return: parameters of q(z|x), (MB, hid_dim)\n",
    "        \"\"\"\n",
    "        xy = torch.cat([x, y], dim=1)\n",
    "        \n",
    "        intermediate = self.encoder_x_to_z(x)\n",
    "        z_mu = self.mu_x_to_z(intermediate)\n",
    "        z_logvar = self.mu_x_to_z(intermediate)\n",
    "        \n",
    "        intermediate = self.encoder_xy_to_w(xy)\n",
    "        w_mu_encoder = self.mu_xy_to_w(intermediate)\n",
    "        w_logvar_encoder = self.mu_xy_to_w(intermediate)\n",
    "        \n",
    "        intermediate = self.encoder_y_to_w(y)\n",
    "        w_mu_prior = self.mu_y_to_w(intermediate)\n",
    "        w_logvar_prior = self.mu_y_to_w(intermediate)\n",
    "        \n",
    "        return w_mu_encoder, w_logvar_encoder, w_mu_prior, \\\n",
    "               w_logvar_prior, z_mu, z_logvar\n",
    "    \n",
    "    def p_x(self, z, w):\n",
    "        \"\"\"\n",
    "        GENERATIVE DISTRIBUTION\n",
    "        :param z: latent vector          (MB, hid_dim)\n",
    "        :return: parameters of p(x|z)    (MB, inp_dim)\n",
    "        \"\"\"\n",
    "        \n",
    "        zw = torch.cat([z, w], dim=1)\n",
    "        \n",
    "        intermediate = self.decoder_zw_to_x(zw)\n",
    "        mu = self.mu_zw_to_x(intermediate)\n",
    "        logvar = self.logvar_zw_to_x(intermediate)\n",
    "        \n",
    "        return mu, logvar\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\n",
    "        Encode the image, sample z and decode \n",
    "        :param x: input image\n",
    "        :return: parameters of p(x|z_hat), z_hat, parameters of q(z|x)\n",
    "        \"\"\"\n",
    "        w_mu_encoder, w_logvar_encoder, w_mu_prior, \\\n",
    "            w_logvar_prior, z_mu, z_logvar = self.q_zw(x, y)\n",
    "        w_encoder = self.reparameterize(w_mu_encoder, w_logvar_encoder)\n",
    "        w_prior = self.reparameterize(w_mu_prior, w_logvar_prior)\n",
    "        z = self.reparameterize(z_mu, z_logvar)\n",
    "        zw = torch.cat([z, w_encoder], dim=1)\n",
    "        \n",
    "        x_mu, x_logvar = self.p_x(z, w_encoder)\n",
    "        y_pred = self.decoder_z_to_y(z)\n",
    "        \n",
    "        return x_mu, x_logvar, zw, y_pred, \\\n",
    "               w_mu_encoder, w_logvar_encoder, w_mu_prior, \\\n",
    "               w_logvar_prior, z_mu, z_logvar\n",
    "\n",
    "    def calculate_loss(self, x, y):\n",
    "        \"\"\"\n",
    "        Given the input batch, compute the negative ELBO \n",
    "        :param x:   (MB, inp_dim)\n",
    "        :param beta: Float\n",
    "        :param average: Compute average over mini batch or not, bool\n",
    "        :return: -RE + beta * KL  (MB, ) or (1, )\n",
    "        \"\"\"\n",
    "        x_mu, x_logvar, zw, y_pred, \\\n",
    "            w_mu_encoder, w_logvar_encoder, w_mu_prior, \\\n",
    "            w_logvar_prior, z_mu, z_logvar = self.forward(x, y)\n",
    "        \n",
    "        x_recon = nn.MSELoss()(x_mu, x)\n",
    "        \n",
    "        w_dist = dists.MultivariateNormal(w_mu_encoder.flatten(), torch.diag(w_logvar_encoder.flatten().exp()))\n",
    "        w_prior = dists.MultivariateNormal(w_mu_prior.flatten(), torch.diag(w_logvar_prior.flatten().exp()))\n",
    "        w_kl = dists.kl.kl_divergence(w_dist, w_prior)\n",
    "        \n",
    "        z_dist = dists.MultivariateNormal(z_mu.flatten(), torch.diag(z_logvar.flatten().exp()))\n",
    "        z_prior = dists.MultivariateNormal(torch.zeros(self.z_dim * z_mu.size()[0]), torch.eye(self.z_dim * z_mu.size()[0]))\n",
    "        z_kl = dists.kl.kl_divergence(z_dist, z_prior)\n",
    "        \n",
    "        y_pred_negentropy = (y_pred.log() * y_pred + (1-y_pred).log() * (1-y_pred)).mean()\n",
    "\n",
    "        y_recon = nn.BCELoss()(y_pred, y)\n",
    "        # alternatively use predicted logvar too to evaluate density of input\n",
    "        \n",
    "        # ELBO does not include y_recon because it should be optimized separately\n",
    "        ELBO = 20 * x_recon + 0.2 * z_kl + 1 * w_kl + 10 * y_pred_negentropy\n",
    "        \n",
    "        return ELBO, x_recon, w_kl, z_kl, y_pred_negentropy, y_recon\n",
    "\n",
    "#     def reconstruct_x(self, x, y):\n",
    "#         x_mean, _, _, _, _ = self.forward(x, y)\n",
    "#         return x_mean\n",
    "\n",
    "#     def calculate_nll(self, X, samples=5000):\n",
    "#         \"\"\"\n",
    "#         Estimate NLL by importance sampling\n",
    "#         :param X: dataset, (N, inp_dim)\n",
    "#         :param samples: Samples per observation\n",
    "#         :return: IS estimate\n",
    "#         \"\"\"   \n",
    "#         prob_sum = 0.\n",
    "\n",
    "#         for i in range(samples):\n",
    "#             KL, RE, _ = self.calculate_loss(X)\n",
    "#             prob_sum += (KL + RE).exp_()\n",
    "            \n",
    "#         return - (prob_sum / samples).sum().log_()\n",
    "\n",
    "#     def generate_x(self, N=25):\n",
    "#         \"\"\"\n",
    "#         Sample, using you VAE: sample z from prior and decode it \n",
    "#         :param N: number of samples\n",
    "#         :return: X (N, inp_size)\n",
    "#         \"\"\"\n",
    "\n",
    "#         m = MultivariateNormal(torch.zeros(self.z_dim + self.w_dim), torch.eye(self.z_dim + self.w_dim))\n",
    "#         z = m.sample(sample_shape=torch.Size([N])) \n",
    "        \n",
    "#         X, _ = self.p_x(z.cuda())\n",
    "#         return X\n",
    "\n",
    "    @staticmethod\n",
    "    def reparameterize(mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = torch.FloatTensor(std.size()).normal_().to(mu.device)\n",
    "        return eps.mul(std).add_(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, manifold_x = make_swiss_roll(n_samples=10000)\n",
    "x = x.astype(np.float32)\n",
    "y = (x[:, 0:1] >= 10).astype(np.float32)\n",
    "z_dim = 2\n",
    "w_dim = 2\n",
    "\n",
    "batch_size = 32\n",
    "beta = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_tensor = torch.from_numpy(x)\n",
    "train_set_y_tensor = torch.from_numpy(y)\n",
    "train_set = utils.TensorDataset(train_set_x_tensor, train_set_y_tensor)\n",
    "train_loader = utils.DataLoader(train_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CSVAE(input_dim=x.shape[1], labels_dim=y.shape[1], z_dim=z_dim, w_dim=w_dim)\n",
    "model = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_without_delta = [param for name, param in model.named_parameters() if 'decoder_z_to_y' not in name]\n",
    "params_delta = [param for name, param in model.named_parameters() if 'decoder_z_to_y' in name]\n",
    "\n",
    "opt_without_delta = optim.Adam(params_without_delta, lr=(1e-3)/2)\n",
    "scheduler_without_delta = optim.lr_scheduler.MultiStepLR(opt_without_delta, milestones=[pow(3, i) for i in range(7)], gamma=pow(0.1, 1/7))\n",
    "opt_delta = optim.Adam(params_delta, lr=(1e-3)/2)\n",
    "scheduler_delta = optim.lr_scheduler.MultiStepLR(opt_delta, milestones=[pow(3, i) for i in range(7)], gamma=pow(0.1, 1/7))\n",
    "n_epochs = 2300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/2300 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1/2300 [00:05<3:14:08,  5.07s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train\n",
      "MSE(x): 79.7222\n",
      "KL(w): 173.0276\n",
      "KL(z): 1.6937\n",
      "-H(y): -0.6267\n",
      "BCE(y): 1.6937\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 2/2300 [00:10<3:14:14,  5.07s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train\n",
      "MSE(x): 74.9843\n",
      "KL(w): 29.5246\n",
      "KL(z): 1.0351\n",
      "-H(y): -0.5753\n",
      "BCE(y): 1.0351\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 3/2300 [00:15<3:14:40,  5.09s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "Train\n",
      "MSE(x): 66.8031\n",
      "KL(w): 22.2326\n",
      "KL(z): 7.0930\n",
      "-H(y): -0.5479\n",
      "BCE(y): 7.0930\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 4/2300 [00:20<3:14:48,  5.09s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n",
      "Train\n",
      "MSE(x): 50.1112\n",
      "KL(w): 23.5048\n",
      "KL(z): 121.5747\n",
      "-H(y): -0.5079\n",
      "BCE(y): 121.5747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 5/2300 [00:25<3:11:57,  5.02s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      "Train\n",
      "MSE(x): 42.1604\n",
      "KL(w): 20.9831\n",
      "KL(z): 162.8066\n",
      "-H(y): -0.4837\n",
      "BCE(y): 162.8066\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 6/2300 [00:30<3:12:44,  5.04s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n",
      "Train\n",
      "MSE(x): 38.4772\n",
      "KL(w): 17.0019\n",
      "KL(z): 177.0185\n",
      "-H(y): -0.4667\n",
      "BCE(y): 177.0185\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 7/2300 [00:35<3:12:10,  5.03s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n",
      "Train\n",
      "MSE(x): 35.7037\n",
      "KL(w): 12.5554\n",
      "KL(z): 199.2492\n",
      "-H(y): -0.4567\n",
      "BCE(y): 199.2492\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 8/2300 [00:40<3:17:28,  5.17s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n",
      "Train\n",
      "MSE(x): 33.9245\n",
      "KL(w): 10.2665\n",
      "KL(z): 213.8956\n",
      "-H(y): -0.4479\n",
      "BCE(y): 213.8956\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 9/2300 [00:45<3:17:07,  5.16s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n",
      "Train\n",
      "MSE(x): 32.6222\n",
      "KL(w): 10.2614\n",
      "KL(z): 212.0925\n",
      "-H(y): -0.4412\n",
      "BCE(y): 212.0925\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 10/2300 [00:50<3:13:57,  5.08s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n",
      "Train\n",
      "MSE(x): 31.6071\n",
      "KL(w): 11.3741\n",
      "KL(z): 207.3359\n",
      "-H(y): -0.4346\n",
      "BCE(y): 207.3359\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 11/2300 [00:56<3:16:34,  5.15s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n",
      "Train\n",
      "MSE(x): 30.7245\n",
      "KL(w): 13.1788\n",
      "KL(z): 200.8286\n",
      "-H(y): -0.4308\n",
      "BCE(y): 200.8286\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|          | 12/2300 [01:01<3:20:14,  5.25s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11\n",
      "Train\n",
      "MSE(x): 29.8397\n",
      "KL(w): 15.1471\n",
      "KL(z): 196.4426\n",
      "-H(y): -0.4270\n",
      "BCE(y): 196.4426\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|          | 13/2300 [01:07<3:21:19,  5.28s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12\n",
      "Train\n",
      "MSE(x): 28.7774\n",
      "KL(w): 17.6959\n",
      "KL(z): 190.9102\n",
      "-H(y): -0.4247\n",
      "BCE(y): 190.9102\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|          | 14/2300 [01:11<3:15:34,  5.13s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13\n",
      "Train\n",
      "MSE(x): 27.6793\n",
      "KL(w): 20.1448\n",
      "KL(z): 185.9779\n",
      "-H(y): -0.4200\n",
      "BCE(y): 185.9779\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|          | 15/2300 [01:17<3:16:59,  5.17s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14\n",
      "Train\n",
      "MSE(x): 26.7428\n",
      "KL(w): 22.7043\n",
      "KL(z): 181.0960\n",
      "-H(y): -0.4172\n",
      "BCE(y): 181.0960\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|          | 16/2300 [01:22<3:20:19,  5.26s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15\n",
      "Train\n",
      "MSE(x): 26.2518\n",
      "KL(w): 24.5631\n",
      "KL(z): 176.1801\n",
      "-H(y): -0.4171\n",
      "BCE(y): 176.1801\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|          | 17/2300 [01:27<3:17:33,  5.19s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16\n",
      "Train\n",
      "MSE(x): 25.5986\n",
      "KL(w): 25.9256\n",
      "KL(z): 172.0957\n",
      "-H(y): -0.4127\n",
      "BCE(y): 172.0957\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|          | 18/2300 [01:32<3:13:39,  5.09s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17\n",
      "Train\n",
      "MSE(x): 25.1093\n",
      "KL(w): 27.3364\n",
      "KL(z): 168.1360\n",
      "-H(y): -0.4108\n",
      "BCE(y): 168.1360\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-caf17daeca72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcur_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_recon_loss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_kl_loss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_kl_loss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_negentropy_loss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_recon_loss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcur_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# optimization could be done more precisely but less efficiently by only updating delta or other params on a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-4ae331f33e34>\u001b[0m in \u001b[0;36mcalculate_loss\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mx_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_logvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mw_mu_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_logvar_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_mu_prior\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mw_logvar_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_logvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mx_recon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-4ae331f33e34>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \"\"\"\n\u001b[1;32m     80\u001b[0m         \u001b[0mw_mu_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_logvar_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_mu_prior\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mw_logvar_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_logvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_zw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mw_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_mu_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_logvar_encoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mw_prior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_mu_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_logvar_prior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-4ae331f33e34>\u001b[0m in \u001b[0;36mq_zw\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mintermediate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_xy_to_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mw_mu_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu_xy_to_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mw_logvar_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu_xy_to_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_recon_losses = []\n",
    "w_kl_losses = []\n",
    "z_kl_losses = []\n",
    "y_negentropy_losses = []\n",
    "y_recon_losses = []\n",
    "for epoch_i in trange(n_epochs):\n",
    "    for cur_batch in train_loader:\n",
    "        loss_val, x_recon_loss_val, w_kl_loss_val, z_kl_loss_val, y_negentropy_loss_val, y_recon_loss_val = model.calculate_loss(*cur_batch)\n",
    "        \n",
    "        # optimization could be done more precisely but less efficiently by only updating delta or other params on a batch\n",
    "        \n",
    "        opt_delta.zero_grad()\n",
    "        y_recon_loss_val.backward(retain_graph=True)\n",
    "        opt_delta.step()\n",
    "        \n",
    "        opt_without_delta.zero_grad()\n",
    "        loss_val.backward()\n",
    "        opt_without_delta.step()\n",
    "        \n",
    "        x_recon_losses.append(x_recon_loss_val.item())\n",
    "        w_kl_losses.append(w_kl_loss_val.item())\n",
    "        z_kl_losses.append(z_kl_loss_val.item())\n",
    "        y_negentropy_losses.append(y_negentropy_loss_val.item())\n",
    "        y_recon_losses.append(y_recon_loss_val.item())\n",
    "    scheduler_without_delta.step()\n",
    "    scheduler_delta.step()\n",
    "    print(f'Epoch {epoch_i}')\n",
    "    \n",
    "    print('Train')\n",
    "    print(f'MSE(x): {np.array(x_recon_losses[-len(train_loader):]).mean():.4f}')\n",
    "    print(f'KL(w): {np.array(w_kl_losses[-len(train_loader):]).mean():.4f}')\n",
    "    print(f'KL(z): {np.array(z_kl_losses[-len(train_loader):]).mean():.4f}')\n",
    "    print(f'-H(y): {np.array(y_negentropy_losses[-len(train_loader):]).mean():.4f}')\n",
    "    print(f'BCE(y): {np.array(z_kl_losses[-len(train_loader):]).mean():.4f}')\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, manifold_x_test = make_swiss_roll(n_samples=10000)\n",
    "x_test = x_test.astype(np.float32)\n",
    "test_set_tensor = torch.from_numpy(x_test)\n",
    "# mu_x, logvar_x, z_hat, mu_z, logvar_z = model.forward(test_set_tensor)\n",
    "\n",
    "# labels_test = (x_test[:, 0:1] >= 10)\n",
    "# colors_test = ['red' if label[0] else 'blue' for label in labels_test]\n",
    "\n",
    "# z_hat = z_hat.detach().numpy()\n",
    "# z_comp = z_hat[:, :2]\n",
    "# w_comp = z_hat[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, manifold_x_test = make_swiss_roll(n_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usual VAE results\n",
    "\n",
    "plt.figure(figsize=(5, 5,))\n",
    "plt.title('(z1, z2)')\n",
    "plt.scatter(z_comp[:, 0], z_comp[:, 1], c=colors_test)\n",
    "\n",
    "plt.figure(figsize=(5, 5,))\n",
    "plt.title('(z2, w1)')\n",
    "plt.scatter(z_comp[:, 1], w_comp[:, 0], c=colors_test)\n",
    "\n",
    "plt.figure(figsize=(5, 5,))\n",
    "plt.title('(w1, w2)')\n",
    "plt.scatter(w_comp[:, 0], w_comp[:, 1], c=colors_test)\n",
    "\n",
    "plt.figure(figsize=(5, 5,))\n",
    "plt.title('(w2, z1)')\n",
    "plt.scatter(w_comp[:, 1], w_comp[:, 0], c=colors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
